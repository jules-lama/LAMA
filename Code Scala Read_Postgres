package fr.esgi.spark

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.{col, substring, _}

object DataFrame1 {

  def main(args: Array[String]): Unit = {

    val spark = SparkSession.builder().appName("b4starScala").master("local[2]").getOrCreate()

    // Note: JDBC loading and saving can be achieved via either the load/save or jdbc methods
    // Loading data from a JDBC source
    val jdbcDF = spark.read
      .format("jdbc")
      .option("url", "jdbc:postgresql://b4db-stg.cqhue3uoeaeg.eu-central-1.rds.amazonaws.com:5432/b4db")
      .option("dbtable", "public.post")
      .option("user", "postgres")
      .option("password", "fabfab91")
      .load()

    //val connectionProperties = new Properties()
    //connectionProperties.put("user", "postgres")
    //connectionProperties.put("password", "fabfab91")
    //val jdbcDF2 = spark.read
    //  .jdbc("jdbc:postgresql://b4db-stg.cqhue3uoeaeg.eu-central-1.rds.amazonaws.com:5432/b4db", "public.post", connectionProperties)


    // Saving data to a JDBC source
    //jdbcDF.write
    //  .format("jdbc")
    //  .option("url", "jdbc:postgresql://b4db-stg.cqhue3uoeaeg.eu-central-1.rds.amazonaws.com:5432/b4db")
    //  .option("dbtable", "public.post")
    //  .option("user", "postgres")
    //  .option("password", "fabfab91")
    //  .save()

    //jdbcDF2.write
    //  .jdbc("jdbc:postgresql://b4db-stg.cqhue3uoeaeg.eu-central-1.rds.amazonaws.com:5432/b4db", "public.post", connectionProperties)
    /*
        // Specifying create table column data types on write
        jdbcDF.write
          .option("createTableColumnTypes", "name CHAR(64), comments VARCHAR(1024)")
          .jdbc("jdbc:postgresql:dbserver", "schema.tablename", connectionProperties)

     */

    val post = jdbcDF.show()

    //val df = spark.sql("SELECT * FROM post")
    //println(df)


  }

}
